{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# from pycaret.time_series import TSForecastingExperiment\n",
    "import calplot\n",
    "import os\n",
    "import plotly\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from heatmap import corrplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import datetime\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\", {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_time'] = pd.to_datetime(df['Unnamed: 0'], format='%Y-%m-%d %H:%M:%S')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = df.set_index('date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCV1 = df[df.columns[df.columns.str.startswith('CV1')].tolist()]\n",
    "dfCV2 = df[df.columns[df.columns.str.startswith('CV2')].tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_idf1 = pd.read_csv('../dataset_2_idf1_2min.csv')\n",
    "\n",
    "df_new_CV1 = df_new_idf1[df_new_idf1.columns[df_new_idf1.columns.str.startswith('CV1')].tolist()]\n",
    "\n",
    "\n",
    "df_new_CV1['date_time'] = pd.to_datetime(df_new_idf1['Unnamed: 0'].apply(lambda x: x.split('+')[0]), format='%Y-%m-%d %H:%M:%S')\n",
    "df_new_CV1 = df_new_CV1.set_index('date_time')\n",
    "df_new_CV1 = df_new_CV1.resample('2min').bfill()\n",
    "\n",
    "df_new_idf2 = pd.read_csv('../dataset_2_idf2_2min_complete.csv')\n",
    "\n",
    "df_new_CV2 = df_new_idf2[df_new_idf2.columns[df_new_idf2.columns.str.startswith('CV2')].tolist()]\n",
    "\n",
    "\n",
    "df_new_CV2['date_time'] = pd.to_datetime(df_new_idf2['timestamp'].apply(lambda x: x.split('+')[0]), format='%Y-%m-%d %H:%M:%S')\n",
    "df_new_CV2 = df_new_CV2.set_index('date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCV1 = pd.concat([dfCV1, df_new_CV1], axis=0)\n",
    "dfCV1 = dfCV1.drop(columns=['XXXXXXXXXXX'])\n",
    "\n",
    "dfCV2 = pd.concat([dfCV2, df_new_CV2], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select IDF 1 or 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF = 'CV2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IDF == 'CV1':\n",
    "    dfAux = dfCV1\n",
    "else:\n",
    "    dfAux = dfCV2\n",
    "\n",
    "dfAux.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_dict = {\n",
    "    'XXXXXXXXXXX' \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_order = ['XXXXXXXXXXX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "[result.append(item) for item in grouping_order if item not in result]\n",
    "# Ordering for the heatmaps\n",
    "grouping_order = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = f'{IDF}/general'\n",
    "# os.makedirs(base_dir, exist_ok=True)\n",
    "# df_IDF1_year = dfAux\n",
    "# # df_IDF1_year[~df_IDF1_year.isna()] = 1\n",
    "# # Time Series summary\n",
    "# df_IDF1_year.describe().to_html(base_dir + '/df_summary.html')\n",
    "# # Cross correlation heatmap\n",
    "# sns.set(color_codes=True, font_scale=0.6)\n",
    "# plt.figure(figsize=(12, 11))\n",
    "\n",
    "# df_IDF1_year = df_IDF1_year[[f'{IDF}.' + x for x in grouping_order if f'{IDF}.' + x in df_IDF1_year.columns]]\n",
    "# corrplot(df_IDF1_year.corr(), size_scale=80)\n",
    "# plt.savefig(base_dir + '/correlation_heatmap.png', bbox_inches='tight')\n",
    "# plt.close()\n",
    "# # Feature-wise analysis\n",
    "# for col in df_IDF1_year.columns[:-1]:\n",
    "#     os.makedirs(base_dir + '/' + col, exist_ok=True)\n",
    "#     eda = TSForecastingExperiment()\n",
    "#     fig_kwargs={'renderer': 'notebook'}\n",
    "#     eda.setup(data=df_IDF1_year[col], fig_kwargs=fig_kwargs, target=col, numeric_imputation_target='mean', verbose=0)\n",
    "#     # Time Series plot\n",
    "#     eda.plot_model(save=base_dir + '/' + col + '/')\n",
    "#     # Auto-correlation plot\n",
    "#     eda.plot_model(plot='acf', save=base_dir + '/' + col + '/')\n",
    "#     # Partial auto-correlation plot\n",
    "#     eda.plot_model(plot='pacf', save=base_dir + '/' + col + '/')\n",
    "#     # Seasonal decomposition plot\n",
    "#     eda.plot_model(plot='decomp', save=base_dir + '/' + col + '/')\n",
    "#     # Histogram and KDE plot\n",
    "#     sns.displot(df_IDF1_year, x=col, kde=True, alpha=0.5)\n",
    "#     plt.savefig(base_dir + '/' + col + '/histogram_KDE.png', bbox_inches='tight')\n",
    "#     plt.close()\n",
    "\n",
    "#     # Frequency heatmap plot\n",
    "#     calplot.calplot(dfAux[col], cmap=\"BuGn\", colorbar=True)\n",
    "#     plt.savefig(base_dir + '/' + col + '/frequency_heatmap.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yearly Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2023: 'XXXXXXXXXXX' was constant and threw error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year in [2021, 2022, 2023]:\n",
    "#     base_dir = f'{IDF}/{str(year)}'\n",
    "#     os.makedirs(base_dir, exist_ok=True)\n",
    "#     df_IDF1_year = dfAux[dfAux.index.to_series().dt.year == year]\n",
    "#     # Time Series summary\n",
    "#     df_IDF1_year.describe().to_html(base_dir + '/df_summary.html')\n",
    "#     # Cross correlation heatmap\n",
    "#     sns.set(color_codes=True, font_scale=0.6)\n",
    "#     plt.figure(figsize=(12, 11))\n",
    "#     corrplot(df_IDF1_year.iloc[:, :-1].corr(), size_scale=80)\n",
    "#     plt.savefig(base_dir + '/correlation_heatmap.png', bbox_inches='tight')\n",
    "#     plt.close()\n",
    "#     # Feature-wise analysis\n",
    "#     for col in df_IDF1_year.columns[:-1]:\n",
    "#         os.makedirs(base_dir + '/' + col, exist_ok=True)\n",
    "#         eda = TSForecastingExperiment()\n",
    "#         fig_kwargs={'renderer': 'notebook'}\n",
    "#         eda.setup(data=df_IDF1_year[col], fig_kwargs=fig_kwargs, target=col, numeric_imputation_target='mean', verbose=0)\n",
    "#         # Time Series plot\n",
    "#         eda.plot_model(save=base_dir + '/' + col + '/')\n",
    "#         # Auto-correlation plot\n",
    "#         eda.plot_model(plot='acf', save=base_dir + '/' + col + '/')\n",
    "#         # Partial auto-correlation plot\n",
    "#         eda.plot_model(plot='pacf', save=base_dir + '/' + col + '/')\n",
    "#         # Seasonal decomposition plot\n",
    "#         eda.plot_model(plot='decomp', save=base_dir + '/' + col + '/')\n",
    "#         # Augmented Dickey Fuller test\n",
    "#         eda.check_stats(test='adf').to_html(base_dir + '/' + col + '/ADFTest.html')\n",
    "#         # Histogram and KDE plot\n",
    "#         sns.displot(df_IDF1_year, x=col, kde=True, alpha=0.5)\n",
    "#         plt.savefig(base_dir + '/' + col + '/histogram_KDE.png', bbox_inches='tight')\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interval-specific Analysis: Normal period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_day = '2021-12-06 00:00:00'\n",
    "end_day = '2022-02-20 23:58:00'\n",
    "\n",
    "start_day = pd.to_datetime(start_day, format='%Y-%m-%d %H:%M:%S')\n",
    "end_day = pd.to_datetime(end_day, format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'XXXXXXXXXXX' was constant and threw error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = f'{IDF}/normal_period'\n",
    "# os.makedirs(base_dir, exist_ok=True)\n",
    "# df_IDF1_year = dfAux[dfAux.index.to_series().between(start_day, end_day)]\n",
    "# # Time Series summary\n",
    "# df_IDF1_year.describe().to_html(base_dir + '/df_summary.html')\n",
    "# # Cross correlation heatmap\n",
    "# sns.set(color_codes=True, font_scale=0.6)\n",
    "# plt.figure(figsize=(12, 11))\n",
    "# df_IDF1_year = df_IDF1_year[[f'{IDF}.' + x for x in grouping_order if f'{IDF}.' + x in df_IDF1_year.columns]]\n",
    "# corrplot(df_IDF1_year.iloc[:, :-1].corr(), size_scale=80)\n",
    "# plt.savefig(base_dir + '/correlation_heatmap.png', bbox_inches='tight')\n",
    "# plt.close()\n",
    "# for col in df_IDF1_year.columns[:-1]:\n",
    "#     os.makedirs(base_dir + '/' + col, exist_ok=True)\n",
    "#     eda = TSForecastingExperiment()\n",
    "#     fig_kwargs={'renderer': 'notebook'}\n",
    "#     eda.setup(data=df_IDF1_year[col], fig_kwargs=fig_kwargs, target=col, numeric_imputation_target='mean', verbose=0)\n",
    "#     # Time Series plot\n",
    "#     eda.plot_model(save=base_dir + '/' + col + '/')\n",
    "#     # Auto-correlation plot\n",
    "#     eda.plot_model(plot='acf', save=base_dir + '/' + col + '/')\n",
    "#     # Partial auto-correlation plot\n",
    "#     eda.plot_model(plot='pacf', save=base_dir + '/' + col + '/')\n",
    "#     # Seasonal decomposition plot\n",
    "#     eda.plot_model(plot='decomp', save=base_dir + '/' + col + '/')\n",
    "#     # Augmented Dickey Fuller test\n",
    "#     eda.check_stats(test='adf').to_html(base_dir + '/' + col + '/ADFTest.html')\n",
    "#     # Histogram and KDE plot\n",
    "#     sns.displot(df_IDF1_year, x=col, kde=True, alpha=0.5)\n",
    "#     plt.savefig(base_dir + '/' + col + '/histogram_KDE.png', bbox_inches='tight')\n",
    "#     plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for period in ['2021', '2022', '2023', 'general', 'normal_period']:\n",
    "    for col in dfAux.columns[:-1]:\n",
    "        try:\n",
    "            html_df = pd.read_html(f'{IDF}/{period}' + '/' + col + '/ADFTest.html')[0]\n",
    "        except ValueError:\n",
    "            continue\n",
    "        # Check on failed tests\n",
    "        if html_df.iloc[0, 6] != 'True':\n",
    "            print(period + '/' + col + '\\t', f'\\t\\tp-value={html_df.iloc[1, 6]}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for period in ['normal_period']:\n",
    "    for col in [\"XXXXXXXXXXX\"]:\n",
    "        try:\n",
    "            html_df = pd.read_html(f'{IDF}/{period}' + '/' + f'{IDF}.' + col + '/ADFTest.html')[0]\n",
    "        except ValueError:\n",
    "            print('NaN')\n",
    "            continue\n",
    "        if html_df.iloc[0, 6] != 'True':\n",
    "            print(col , f'{html_df.iloc[1, 6]}', \"False\" )\n",
    "        else:\n",
    "            print(col , f'{html_df.iloc[1, 6]}', \"True\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonality with PyCaret (IDF1 only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IDF == 'CV1':\n",
    "    season_df = pd.DataFrame(columns=['period'] + dfAux.columns[:-1].tolist())\n",
    "    for period in ['2021', '2022', '2023', 'general', 'normal_period']:\n",
    "        row = list()\n",
    "        row.append(period)\n",
    "        for col in dfAux.columns[:-1]:\n",
    "            try:\n",
    "                with open(f'{IDF}/{period}' + '/' + col + '/Classical Decomposition.html', 'r') as f:\n",
    "                    html_file = f.read()\n",
    "            except (ValueError, FileNotFoundError):\n",
    "                continue\n",
    "            row.append(int(re.search(r'Seasonal Period = \\d{1,2}', html_file).group().split(' ')[-1]))\n",
    "        season_df = pd.concat([pd.DataFrame(np.array(row).reshape(1, -1), columns=season_df.columns), season_df])\n",
    "    season_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto Correlation (also for seasonality checks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 'normal_period'\n",
    "for col in dfAux.columns[:-1]:\n",
    "    try:\n",
    "        with open(f'{IDF}/{period}' + '/' + col + '/Auto Correlation (ACF).html', 'r') as f:\n",
    "            html_file = f.read()\n",
    "    except (ValueError, FileNotFoundError):\n",
    "        continue\n",
    "    list_str = re.search(r'\"mode\":\"markers\",\"name\":\"ACF\",\"x\":\\[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40\\],\"y\":\\[(.*?)\\]', html_file).group().split(',\"y\":')[-1]\n",
    "    list_str = list_str[1:-1].split(',')\n",
    "    if list_str[0] == 'null':\n",
    "        continue\n",
    "    list_str = [float(x) for x in list_str]\n",
    "    # print(translation_dict[col] if (np.argmax(list_str[15:]) + 14 >=25) and (np.argmax(list_str[15:]) + 14 <=30) else '')\n",
    "    # print(f'\\'{col}\\', {np.argmax(list_str[15:] )+ 14}, True' if (np.argmax(list_str[15:]) + 14 >=25) and (np.argmax(list_str[15:]) + 14 <=30) else f'\\'{col}\\', {np.argmax(list_str[15:] )}, False')\n",
    "    print(f'{translation_dict[col]}, {np.argmax(list_str[15:] )+ 14}, True' if (np.argmax(list_str[15:]) + 14 >=25) and (np.argmax(list_str[15:]) + 14 <=30) else f'{translation_dict[col]}, {np.argmax(list_str[:] )}, False')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sequences(ids:list[str], data_set: pd.DataFrame, start_day:datetime.datetime, end_day:datetime.datetime):\n",
    "    num_plots = len(ids)\n",
    "    fig = make_subplots(rows=num_plots, cols=1, subplot_titles=[translation_dict[id] for id in ids])\n",
    "\n",
    "    data_set = data_set[data_set.index.to_series().between(start_day, end_day)]\n",
    "    for i, seq_id in enumerate(ids):\n",
    "        fig.append_trace(go.Scatter(\n",
    "            mode='lines',\n",
    "            x=data_set[seq_id].index,\n",
    "            y=data_set[seq_id].values,\n",
    "            marker=dict(\n",
    "                line=dict(\n",
    "                    width=.01\n",
    "                )\n",
    "            ),\n",
    "            \n",
    "\n",
    "        ), row=i+1, col=1)\n",
    "\n",
    "    title_text = \"Time Series plot for period:\".ljust(87) + start_day.strftime('%Y-%m-%d %H:%M||') + end_day.strftime('%Y-%m-%d %H:%M')\n",
    "    fig.update_xaxes(matches='x')\n",
    "    fig.update_layout(height=num_plots*300, width=1400, title_text=title_text, showlegend=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sequences_together(ids:list[str], data_set: pd.DataFrame, start_day:datetime.datetime, end_day:datetime.datetime):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    data_set = data_set[data_set.index.to_series().between(start_day, end_day)]\n",
    "\n",
    "    traces = []\n",
    "    buttons = []\n",
    "    for i, seq_id in enumerate(ids):\n",
    "        traces.append(go.Scatter(\n",
    "                mode='lines',\n",
    "                x=data_set[seq_id].index,\n",
    "                y=scaler.fit_transform(data_set[seq_id].values.reshape(-1, 1)).reshape(1, -1)[0],\n",
    "                marker=dict(\n",
    "                    line=dict(\n",
    "                        width=.01\n",
    "                    )\n",
    "                ),\n",
    "                name=seq_id\n",
    "                \n",
    "\n",
    "            )\n",
    "                    )\n",
    "       \n",
    "        buttons.append(dict(method='restyle',\n",
    "                            label=seq_id,\n",
    "                            visible=True,\n",
    "                            args=[{'visible':True},[i for i,x in enumerate(traces) if x.name == seq_id]],\n",
    "                            args2=[{'visible':'legendonly'},[i for i,x in enumerate(traces) if x.name == seq_id]]\n",
    "                            \n",
    "                            )\n",
    "                    )\n",
    "\n",
    "    allButton = [\n",
    "        dict(\n",
    "            method='restyle',\n",
    "            label='all',\n",
    "            visible=True,\n",
    "            args=[{'visible':True}],\n",
    "            args2=[{'visible':'legendonly'}]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # create the layout \n",
    "    layout = go.Layout(\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                type='buttons',\n",
    "                direction='right',\n",
    "                x=0.9,\n",
    "                y=1.3,\n",
    "                showactive=True,\n",
    "                buttons= allButton + buttons\n",
    "            )\n",
    "        ],\n",
    "        showlegend=True\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=traces,layout=layout)\n",
    "    \n",
    "    \n",
    "\n",
    "    f = fig.full_figure_for_development(warn=False)\n",
    "\n",
    "    title_text = \"Time Series plot for period:\".ljust(87) + start_day.strftime('%Y-%m-%d %H:%M||') + end_day.strftime('%Y-%m-%d %H:%M')\n",
    "    fig.update_xaxes(matches='x')\n",
    "    fig.update_layout(height=400, width=1400, showlegend=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids1 = {\n",
    "    'XXXXXXXXXXX'\n",
    "   \n",
    "}\n",
    "\n",
    "ids2 = {\n",
    "    'XXXXXXXXXXX'\n",
    "}\n",
    "\n",
    "if IDF == 'CV1':\n",
    "    ids = ids1\n",
    "else:\n",
    "    ids = ids2\n",
    "  \n",
    "start_day = '2022-01-26 12:54:00'\n",
    "end_day = '2022-01-26 18:56:00'\n",
    "start_day = pd.to_datetime(start_day, format='%Y-%m-%d %H:%M:%S')\n",
    "end_day = pd.to_datetime(end_day, format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# plot_sequences_together(ids.keys(), dfAux, start_day, end_day)\n",
    "plot_sequences(ids.keys(), dfAux, start_day, end_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN period detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35788, 35790]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rupture_idx = 0\n",
    "rupture_list = list()\n",
    "nan_list = pd.DataFrame(np.where(dfAux.isna())).T.groupby(by=[0]).count().index.tolist()\n",
    "for idx in nan_list:\n",
    "    if rupture_idx == idx-1:\n",
    "        rupture_idx += 1\n",
    "    else:\n",
    "        rupture_list.append(rupture_idx)\n",
    "        rupture_list.append(idx)\n",
    "        rupture_idx = idx\n",
    "rupture_list.append(idx)\n",
    "rupture_list.remove(0)\n",
    "rupture_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Period 0': {'End': '2021-02-19 17:00:00',\n",
      "              'Start': '2021-02-19 16:56:00',\n",
      "              'Time gap': '0 days 00:04:00',\n",
      "              'Variables affected': 27}}\n"
     ]
    }
   ],
   "source": [
    "nan_dict = dict()\n",
    "for idx in range(0, len(rupture_list),  2):\n",
    "   nan_dict[f'Period {idx//2}'] = dict()\n",
    "   start_day = dfAux.index[rupture_list[idx]]\n",
    "   end_day = dfAux.index[rupture_list[idx + 1]]\n",
    "\n",
    "   nan_period = end_day - start_day\n",
    "   nan_dict[f'Period {idx//2}']['Start'] = str(start_day)\n",
    "   nan_dict[f'Period {idx//2}']['End'] = str(end_day)\n",
    "   nan_dict[f'Period {idx//2}']['Time gap'] = str(nan_period)\n",
    "   nan_dict[f'Period {idx//2}']['Variables affected'] = pd.DataFrame(np.where(dfAux.isna())).T.groupby(by=[0]).count().iloc[np.where(np.array(nan_list) == rupture_list[idx])[0]][1].values[0]\n",
    "\n",
    "pp = pprint.PrettyPrinter(depth=4)\n",
    "pp.pprint(nan_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
